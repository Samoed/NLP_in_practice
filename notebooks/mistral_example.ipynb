{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30616,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"### Install dependencies ","metadata":{"execution":{"iopub.status.busy":"2023-12-16T21:25:12.270056Z","iopub.execute_input":"2023-12-16T21:25:12.270494Z","iopub.status.idle":"2023-12-16T21:25:59.438441Z","shell.execute_reply.started":"2023-12-16T21:25:12.270463Z","shell.execute_reply":"2023-12-16T21:25:59.437406Z"}}},{"cell_type":"code","source":"!pip install sentencepiece\n!pip install accelerate\n!pip install -i https://test.pypi.org/simple/ bitsandbytes\n!pip install -U transformers","metadata":{"execution":{"iopub.status.busy":"2023-12-16T21:46:46.039911Z","iopub.execute_input":"2023-12-16T21:46:46.040193Z","iopub.status.idle":"2023-12-16T21:47:49.395955Z","shell.execute_reply.started":"2023-12-16T21:46:46.040148Z","shell.execute_reply":"2023-12-16T21:47:49.394946Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Requirement already satisfied: sentencepiece in /opt/conda/lib/python3.10/site-packages (0.1.99)\nRequirement already satisfied: accelerate in /opt/conda/lib/python3.10/site-packages (0.25.0)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from accelerate) (1.24.3)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from accelerate) (21.3)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from accelerate) (5.9.3)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from accelerate) (6.0.1)\nRequirement already satisfied: torch>=1.10.0 in /opt/conda/lib/python3.10/site-packages (from accelerate) (2.0.0)\nRequirement already satisfied: huggingface-hub in /opt/conda/lib/python3.10/site-packages (from accelerate) (0.19.4)\nRequirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from accelerate) (0.4.1)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->accelerate) (3.0.9)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.12.2)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (4.5.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.1.2)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->accelerate) (2023.12.1)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->accelerate) (2.31.0)\nRequirement already satisfied: tqdm>=4.42.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->accelerate) (4.66.1)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.3)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (3.2.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (2023.11.17)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\nLooking in indexes: https://test.pypi.org/simple/\nCollecting bitsandbytes\n  Obtaining dependency information for bitsandbytes from https://test-files.pythonhosted.org/packages/5c/e0/597d593ec3b6cf5ea7eb4894a545045bd95611de8a316a2a1eaa838a2459/bitsandbytes-0.39.0-py3-none-any.whl.metadata\n  Downloading https://test-files.pythonhosted.org/packages/5c/e0/597d593ec3b6cf5ea7eb4894a545045bd95611de8a316a2a1eaa838a2459/bitsandbytes-0.39.0-py3-none-any.whl.metadata (9.8 kB)\nDownloading https://test-files.pythonhosted.org/packages/5c/e0/597d593ec3b6cf5ea7eb4894a545045bd95611de8a316a2a1eaa838a2459/bitsandbytes-0.39.0-py3-none-any.whl (95.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m95.8/95.8 MB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: bitsandbytes\nSuccessfully installed bitsandbytes-0.39.0\nRequirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.35.2)\nCollecting transformers\n  Obtaining dependency information for transformers from https://files.pythonhosted.org/packages/fc/04/0aad491cd98b09236c54ab849863ee85421eeda5138bbf9d33ecc594652b/transformers-4.36.1-py3-none-any.whl.metadata\n  Downloading transformers-4.36.1-py3-none-any.whl.metadata (126 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m126.8/126.8 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.12.2)\nRequirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.19.4)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.24.3)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0.1)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2023.8.8)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.31.0)\nRequirement already satisfied: tokenizers<0.19,>=0.14 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.15.0)\nRequirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.4.1)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.66.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2023.12.1)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.5.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.0.9)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.2.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2023.11.17)\nDownloading transformers-4.36.1-py3-none-any.whl (8.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.3/8.3 MB\u001b[0m \u001b[31m33.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: transformers\n  Attempting uninstall: transformers\n    Found existing installation: transformers 4.35.2\n    Uninstalling transformers-4.35.2:\n      Successfully uninstalled transformers-4.35.2\nSuccessfully installed transformers-4.36.1\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Load Mistral model","metadata":{}},{"cell_type":"code","source":"from transformers import AutoTokenizer, AutoModelForCausalLM\nimport torch\n\ntokenizer = AutoTokenizer.from_pretrained(\"Open-Orca/Mistral-7B-OpenOrca\")\nmodel = AutoModelForCausalLM.from_pretrained(\"Open-Orca/Mistral-7B-OpenOrca\", torch_dtype=torch.float16,\n    low_cpu_mem_usage=True,\n    use_cache=False,\n    device_map='auto')\n#     load_in_8bit=True)","metadata":{"execution":{"iopub.status.busy":"2023-12-16T21:47:49.398340Z","iopub.execute_input":"2023-12-16T21:47:49.398730Z","iopub.status.idle":"2023-12-16T21:50:29.239654Z","shell.execute_reply.started":"2023-12-16T21:47:49.398692Z","shell.execute_reply":"2023-12-16T21:50:29.238683Z"},"trusted":true},"execution_count":2,"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/1.69k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0cd754e131ce4b0f80767a794725a36f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.model:   0%|          | 0.00/493k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d41a8768c63d40538b4601915d35c6ab"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"added_tokens.json:   0%|          | 0.00/90.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9b5a0266f2ef479292a4b41e7ac3c080"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/101 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3d1a1f28b3e24f5780aba9ea07e7ed51"}},"metadata":{}},{"name":"stderr","text":"Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\nSpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/623 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1fc7a056dc304a72abf7ec2c7865121b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin.index.json:   0%|          | 0.00/23.9k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f241929bd1074273931f57319867a4c9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"666b591dd19c4d1ab91353645735748b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"pytorch_model-00001-of-00002.bin:   0%|          | 0.00/9.94G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1529dc2830e5478e92b1373f7870f7fe"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"pytorch_model-00002-of-00002.bin:   0%|          | 0.00/4.54G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d3779de6009b438c8c1a0525d83b4dc9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"04d851a05f144268807bb39eede1974e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/120 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cb4c938c625d4f1eae682fed6e98af5a"}},"metadata":{}}]},{"cell_type":"markdown","source":"### Sample vacancy ","metadata":{}},{"cell_type":"code","source":"vacancy = \"\"\"\nJob Description\n  \nProject Role :AI Platform Engineer\nProject Role Description :Develops applications and systems that utilize AI to improve performance and efficiency, including but not limited to deep learning, neural networks, chatbots, natural language processing.\nManagement Level :7\nWork Experience: 12-15 years\nWork location: Hyderabad\nMust Have Skills:\nGood To Have Skills:\nJob Requirements:\nKey Responsibilities: \nA: Able to engage with customers for solving business problems leveraging AI,NLP \nB: Identifying applicability of ML,NLP to use cases with ability to project both the business,Technology benefits \nC: Identify ways of embedding,integrating AI,ML services into the enterprise architecture seamlessly \nD: Keep abreast of new technology innovations in the field of NLP, ML,bring it \nE: Good understanding of machine learning algorithms such as CRFs, SVM \nF: Expertise with Python\nTechnical Experience : \nA: Working experience in any of the NLP app areas Sematic Web and Ontologies Machine Translation Sentiment Analysis Document Classification Question Answer Matching Text Summarization Have worked with RNN, LSTM etc \nB: Work exp in creating NLP pipelines for processing large amount of document corpus\nProfessional Attributes : A: Be a self starter and a fast learner \nB: Possess strong problem solving skills with the ability to methodically analyze and resolve tech challenges \nC: Possess strong written, verbal,comm,analyitical,tech,inter personal and presentation skills\nEducational Qualification : \nA: 15years fulltime of Education\nAdditional Information : \nA: Working knowledge of relational and NO SQL database systems\"\"\"","metadata":{"execution":{"iopub.status.busy":"2023-12-16T21:50:29.241045Z","iopub.execute_input":"2023-12-16T21:50:29.241563Z","iopub.status.idle":"2023-12-16T21:50:29.248366Z","shell.execute_reply.started":"2023-12-16T21:50:29.241529Z","shell.execute_reply":"2023-12-16T21:50:29.247386Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"### Sample iconic resume ","metadata":{}},{"cell_type":"code","source":"iconic_resume = \"\"\" Isabella Kim\nisabella@kim.com\n•\n(557) 340-8175\n•\nlinkedin.com/in/isabella-kim\n•\n@isabella.kim\nNLP Engineer\nExperienced NLP Engineer with 4 years of expertise in developing and implementing NLP-based systems to improve accuracy, reduce processing time, and increase customer engagement. Proven track record in detecting and correcting errors in text, resulting in a 25% reduction in customer complaints, and automating text-based tasks, increasing team productivity by 30%. Skilled in analyzing and interpreting text data, researching and evaluating new NLP technologies, and collaborating with cross-functional teams to deliver innovative solutions.\nWORK EXPERIENCE\nNLP Engineer\n03/2022 – Present\nLinguaTech Solutions\nDeveloped and implemented an NLP-based system to detect and correct errors in text, resulting in a 25% reduction in customer complaints related to text errors.\nCollaborated with a team of data scientists to develop and maintain an NLP model to improve accuracy and performance, resulting in a 15% increase in precision and recall metrics.\nDesigned and developed an NLP-based application to automate text-based tasks, reducing manual processing time by 50% and increasing team productivity by 30%.\nData Analyst.\n03/2020 – 03/2022\nDataWave Analytics\nAnalyzed and interpreted text data to identify patterns and trends, providing insights that led to a 10% increase in customer satisfaction scores.\nDeveloped and maintained NLP pipelines to process large volumes of text data, resulting in a 20% reduction in processing time and a 15% increase in data accuracy.\nResearched and evaluated new NLP technologies and techniques, implementing a new algorithm that improved system performance by 30%.\nJunior NLP Engineer\n03/2019 – 03/2020\nInnovateNLP Inc.\nDesigned and implemented an NLP-based system to extract structured data from unstructured text, resulting in a 40% increase in data accuracy and a 25% reduction in processing time.\nDeveloped and maintained NLP-based systems to detect and classify text, improving accuracy by 20% and reducing false positives by 15%.\nDeveloped and maintained NLP-based systems to generate natural language text, resulting in a 30% increase in customer engagement and a 25% increase in revenue.\nSKILLS & COMPETENCIES\nNatural Language Processing (NLP)\nMachine Learning\nDeep Learning\nText Analytics\nData Mining\nPython\nTensorFlow\nPyTorch\nKeras\nNLTK\nSpaCy\nGensim\nSentiment Analysis\nNamed Entity Recognition\nText Classification\nInformation Extraction\nData Visualization\nBig Data Processing\nHadoop\nSpark\nSQL\nGit\nDocker\nRESTful APIs\nAgile Development\nTeam Collaboration\nResearch and Evaluation\nProblem Solving\nCommunication Skills\nCOURSES / CERTIFICATIONS\nNatural Language Processing Professional (NLPP) Certification\n04/2023\nInternational Association of Artificial Intelligence and NLP Professionals (IAAINP)\nData Science and Machine Learning Bootcamp with Python (Udemy)\n04/2022\nUdemy\nAdvanced Natural Language Processing (NLP) with Deep Learning (Coursera)\n04/2021\ndeeplearning.ai\nEDUCATION\nMaster of Science in Natural Language Processing\n2016 - 2020\nUniversity of Washington\nSeattle, WA\nNatural Language Processing\nComputer Science\n\"\"\"","metadata":{"execution":{"iopub.status.busy":"2023-12-16T21:50:29.251055Z","iopub.execute_input":"2023-12-16T21:50:29.251326Z","iopub.status.idle":"2023-12-16T21:50:29.267583Z","shell.execute_reply.started":"2023-12-16T21:50:29.251303Z","shell.execute_reply":"2023-12-16T21:50:29.266732Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"### Sample resume ","metadata":{}},{"cell_type":"code","source":"example_resume = \"\"\"Jarrett Farrell\njarrett@farrell.com\n•\n(234) 567-8901\n•\nlinkedin.com/in/jarrett-farrell\n•\n@jarrett.farrell\nSenior NLP Engineer\nHighly skilled Senior NLP Engineer with a track record of developing and implementing state-of-the-art NLP models, resulting in significant accuracy improvements and increased customer satisfaction. Collaborative team player experienced in optimizing NLP pipelines and integrating models into chatbot systems, driving efficiency gains and reducing response times. Proven ability to research and implement cutting-edge NLP techniques, achieving substantial accuracy improvements and seamless integration into various applications.\nWORK EXPERIENCE\nSenior NLP Engineer\n01/2023 – 04/2023\nCardinal Industries\nDeveloped and implemented a state-of-the-art NLP model for sentiment analysis, resulting in a 25% increase in accuracy compared to existing models.\nCollaborated with a team of data scientists to optimize an NLP pipeline, reducing data pre-processing time by 40% and improving overall model training efficiency.\nIntegrated NLP models into a chatbot system, leading to a 30% reduction in customer support response time and a 20% increase in customer satisfaction.\nNLP Engineer\n09/2022 – 12/2022\nGenesis Global\nResearched and implemented a novel algorithm for text summarization, achieving a 40% improvement in summarization accuracy compared to existing methods.\nDesigned and developed an NLP system for question answering, resulting in a 50% increase in the system's ability to accurately answer user queries.\nCollaborated with product managers to define requirements and successfully launched an NLP-based recommendation system, leading to a 15% increase in user engagement and a 10% increase in revenue.\nNLP Engineer\n07/2022 – 09/2022\nGenesis Global\nDeveloped and maintained a library of NLP models and APIs, enabling seamless integration of NLP capabilities into various applications and reducing development time by 30%.\nImplemented a continuous monitoring system for NLP model performance, resulting in early detection of issues and a 20% improvement in model accuracy over time.\nResearched and implemented cutting-edge NLP techniques for text classification, achieving a 35% increase in accuracy compared to previous models.\nSKILLS & COMPETENCIES\nExpertise in Natural Language Processing (NLP)\nProficiency in Python and NLP libraries such as NLTK, SpaCy, and Gensim\nExperience with machine learning algorithms and deep learning frameworks like TensorFlow and PyTorch\nKnowledge of text summarization and sentiment analysis techniques\nAbility to develop and implement state-of-the-art NLP models\nExperience in optimizing NLP pipelines\nSkills in integrating NLP models into systems like chatbots\nAbility to research and implement novel algorithms for NLP tasks\nExperience in designing and developing NLP systems for question answering\nAbility to collaborate with cross-functional teams, including data scientists and product managers\nExperience in launching NLP-based recommendation systems\nSkills in developing and maintaining a library of NLP models and APIs\nAbility to implement continuous monitoring systems for NLP model performance\nKnowledge of cutting-edge NLP techniques for text classification\nStrong problem-solving skills\nExcellent communication skills\nStrong understanding of linguistics and text representation techniques\nFamiliarity with cloud platforms like AWS, Google Cloud, or Azure\nKnowledge of data pre-processing and cleaning techniques\nUnderstanding of software development methodologies and version control systems like Git.\nCOURSES / CERTIFICATIONS\nCertified Data Scientist (CDS)\n07/2023\nIBM\nNatural Language Processing Specialization by deeplearning.ai (Coursera)\n07/2022\nCoursera\nAdvanced Certification in Artificial Intelligence and Machine Learning by Purdue University (Simplilearn)\n07/2021\nPurdue University (Simplilearn)\nEDUCATION\nMaster of Science in Natural Language Processing\n2010-2014\nUniversity of Washington\n,\nSeattle, WA\nNatural Language Processing\nMachine Learning\n\n\"\"\"","metadata":{"execution":{"iopub.status.busy":"2023-12-16T21:50:29.268774Z","iopub.execute_input":"2023-12-16T21:50:29.269068Z","iopub.status.idle":"2023-12-16T21:50:29.284760Z","shell.execute_reply.started":"2023-12-16T21:50:29.269044Z","shell.execute_reply":"2023-12-16T21:50:29.284004Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"### A bit of prompt engineering","metadata":{}},{"cell_type":"code","source":"prompt = f\"\"\"You are an NLP HR specialist. You need to decide if the person with your resume is suitable for our vacancy. To do this, look at the iconic resume: \\n{iconic_resume} \\n and the vacancy: \\n{vacancy}. Based on this, give an assessment of the relevance of the input resume and the vacancy from 1 to 5 and decide whether we should hire this candidate or not. Input resume: \\n{example_resume} \\n Answer: Let's think step by step...\n\"\"\"","metadata":{"execution":{"iopub.status.busy":"2023-12-16T21:50:29.285943Z","iopub.execute_input":"2023-12-16T21:50:29.286278Z","iopub.status.idle":"2023-12-16T21:50:29.298284Z","shell.execute_reply.started":"2023-12-16T21:50:29.286246Z","shell.execute_reply":"2023-12-16T21:50:29.297563Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"def generate(model, tokenizer, prompt):\n    data = tokenizer(prompt, return_tensors=\"pt\", add_special_tokens=False)\n    data = {k: v.to(model.device) for k, v in data.items()}\n    output_ids = model.generate(\n        **data,\n        max_new_tokens=512, use_cache=True, do_sample=True,\n        temperature=0.2, top_p=0.95\n    )[0]\n    output_ids = output_ids[len(data[\"input_ids\"][0]):]\n    output = tokenizer.decode(output_ids, skip_special_tokens=True)\n    return output.strip()","metadata":{"execution":{"iopub.status.busy":"2023-12-16T21:51:23.367865Z","iopub.execute_input":"2023-12-16T21:51:23.368887Z","iopub.status.idle":"2023-12-16T21:51:23.375280Z","shell.execute_reply.started":"2023-12-16T21:51:23.368853Z","shell.execute_reply":"2023-12-16T21:51:23.374296Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"text = generate(model, tokenizer, prompt)\nprint(text)","metadata":{"execution":{"iopub.status.busy":"2023-12-16T21:51:23.464254Z","iopub.execute_input":"2023-12-16T21:51:23.464554Z","iopub.status.idle":"2023-12-16T21:51:47.794638Z","shell.execute_reply.started":"2023-12-16T21:51:23.464530Z","shell.execute_reply":"2023-12-16T21:51:47.793685Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"1. Relevance of the input resume: The input resume is highly relevant to the vacancy as the candidate has a strong background in NLP, with experience in developing and implementing state-of-the-art NLP models, optimizing NLP pipelines, and integrating models into chatbot systems.\n\n2. Work experience: The candidate has 12 years of experience in the field, which is in line with the job requirements.\n\n3. Skills and competencies: The candidate possesses a wide range of skills and competencies relevant to the position, including expertise in NLP, proficiency in Python, experience with machine learning algorithms and deep learning frameworks, and knowledge of text summarization and sentiment analysis techniques.\n\n4. Education: The candidate has a Master of Science in Natural Language Processing, which is in line with the educational qualification required for the position.\n\n5. Additional information: The candidate has a strong understanding of linguistics and text representation techniques, familiarity with cloud platforms, and knowledge of data pre-processing and cleaning techniques.\n\nBased on the analysis, I would give the input resume a rating of 5 out of 5 and recommend hiring this candidate for the position.\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}