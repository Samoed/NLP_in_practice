{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-16T21:25:12.270494Z",
     "iopub.status.busy": "2023-12-16T21:25:12.270056Z",
     "iopub.status.idle": "2023-12-16T21:25:59.438441Z",
     "shell.execute_reply": "2023-12-16T21:25:59.437406Z",
     "shell.execute_reply.started": "2023-12-16T21:25:12.270463Z"
    }
   },
   "source": [
    "### Install dependencies "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-16T21:46:46.040193Z",
     "iopub.status.busy": "2023-12-16T21:46:46.039911Z",
     "iopub.status.idle": "2023-12-16T21:47:49.395955Z",
     "shell.execute_reply": "2023-12-16T21:47:49.394946Z",
     "shell.execute_reply.started": "2023-12-16T21:46:46.040148Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!pip install sentencepiece\n",
    "!pip install accelerate\n",
    "!pip install -i https://test.pypi.org/simple/ bitsandbytes\n",
    "!pip install -U transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Mistral model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-16T21:47:49.398730Z",
     "iopub.status.busy": "2023-12-16T21:47:49.398340Z",
     "iopub.status.idle": "2023-12-16T21:50:29.239654Z",
     "shell.execute_reply": "2023-12-16T21:50:29.238683Z",
     "shell.execute_reply.started": "2023-12-16T21:47:49.398692Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0cd754e131ce4b0f80767a794725a36f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/1.69k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d41a8768c63d40538b4601915d35c6ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.model:   0%|          | 0.00/493k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b5a0266f2ef479292a4b41e7ac3c080",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "added_tokens.json:   0%|          | 0.00/90.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d1a1f28b3e24f5780aba9ea07e7ed51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/101 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1fc7a056dc304a72abf7ec2c7865121b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/623 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f241929bd1074273931f57319867a4c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin.index.json:   0%|          | 0.00/23.9k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "666b591dd19c4d1ab91353645735748b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1529dc2830e5478e92b1373f7870f7fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model-00001-of-00002.bin:   0%|          | 0.00/9.94G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3779de6009b438c8c1a0525d83b4dc9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model-00002-of-00002.bin:   0%|          | 0.00/4.54G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04d851a05f144268807bb39eede1974e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb4c938c625d4f1eae682fed6e98af5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/120 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import torch\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"Open-Orca/Mistral-7B-OpenOrca\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    \"Open-Orca/Mistral-7B-OpenOrca\",\n",
    "    torch_dtype=torch.float16,\n",
    "    low_cpu_mem_usage=True,\n",
    "    use_cache=False,\n",
    "    device_map=\"auto\",\n",
    ")\n",
    "#     load_in_8bit=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample vacancy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-16T21:50:29.241563Z",
     "iopub.status.busy": "2023-12-16T21:50:29.241045Z",
     "iopub.status.idle": "2023-12-16T21:50:29.248366Z",
     "shell.execute_reply": "2023-12-16T21:50:29.247386Z",
     "shell.execute_reply.started": "2023-12-16T21:50:29.241529Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "vacancy = \"\"\"\n",
    "Job Description\n",
    "  \n",
    "Project Role :AI Platform Engineer\n",
    "Project Role Description :Develops applications and systems that utilize AI to improve performance and efficiency, including but not limited to deep learning, neural networks, chatbots, natural language processing.\n",
    "Management Level :7\n",
    "Work Experience: 12-15 years\n",
    "Work location: Hyderabad\n",
    "Must Have Skills:\n",
    "Good To Have Skills:\n",
    "Job Requirements:\n",
    "Key Responsibilities: \n",
    "A: Able to engage with customers for solving business problems leveraging AI,NLP \n",
    "B: Identifying applicability of ML,NLP to use cases with ability to project both the business,Technology benefits \n",
    "C: Identify ways of embedding,integrating AI,ML services into the enterprise architecture seamlessly \n",
    "D: Keep abreast of new technology innovations in the field of NLP, ML,bring it \n",
    "E: Good understanding of machine learning algorithms such as CRFs, SVM \n",
    "F: Expertise with Python\n",
    "Technical Experience : \n",
    "A: Working experience in any of the NLP app areas Sematic Web and Ontologies Machine Translation Sentiment Analysis Document Classification Question Answer Matching Text Summarization Have worked with RNN, LSTM etc \n",
    "B: Work exp in creating NLP pipelines for processing large amount of document corpus\n",
    "Professional Attributes : A: Be a self starter and a fast learner \n",
    "B: Possess strong problem solving skills with the ability to methodically analyze and resolve tech challenges \n",
    "C: Possess strong written, verbal,comm,analyitical,tech,inter personal and presentation skills\n",
    "Educational Qualification : \n",
    "A: 15years fulltime of Education\n",
    "Additional Information : \n",
    "A: Working knowledge of relational and NO SQL database systems\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample iconic resume "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-16T21:50:29.251326Z",
     "iopub.status.busy": "2023-12-16T21:50:29.251055Z",
     "iopub.status.idle": "2023-12-16T21:50:29.267583Z",
     "shell.execute_reply": "2023-12-16T21:50:29.266732Z",
     "shell.execute_reply.started": "2023-12-16T21:50:29.251303Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "iconic_resume = \"\"\" Isabella Kim\n",
    "isabella@kim.com\n",
    "•\n",
    "(557) 340-8175\n",
    "•\n",
    "linkedin.com/in/isabella-kim\n",
    "•\n",
    "@isabella.kim\n",
    "NLP Engineer\n",
    "Experienced NLP Engineer with 4 years of expertise in developing and implementing NLP-based systems to improve accuracy, reduce processing time, and increase customer engagement. Proven track record in detecting and correcting errors in text, resulting in a 25% reduction in customer complaints, and automating text-based tasks, increasing team productivity by 30%. Skilled in analyzing and interpreting text data, researching and evaluating new NLP technologies, and collaborating with cross-functional teams to deliver innovative solutions.\n",
    "WORK EXPERIENCE\n",
    "NLP Engineer\n",
    "03/2022 – Present\n",
    "LinguaTech Solutions\n",
    "Developed and implemented an NLP-based system to detect and correct errors in text, resulting in a 25% reduction in customer complaints related to text errors.\n",
    "Collaborated with a team of data scientists to develop and maintain an NLP model to improve accuracy and performance, resulting in a 15% increase in precision and recall metrics.\n",
    "Designed and developed an NLP-based application to automate text-based tasks, reducing manual processing time by 50% and increasing team productivity by 30%.\n",
    "Data Analyst.\n",
    "03/2020 – 03/2022\n",
    "DataWave Analytics\n",
    "Analyzed and interpreted text data to identify patterns and trends, providing insights that led to a 10% increase in customer satisfaction scores.\n",
    "Developed and maintained NLP pipelines to process large volumes of text data, resulting in a 20% reduction in processing time and a 15% increase in data accuracy.\n",
    "Researched and evaluated new NLP technologies and techniques, implementing a new algorithm that improved system performance by 30%.\n",
    "Junior NLP Engineer\n",
    "03/2019 – 03/2020\n",
    "InnovateNLP Inc.\n",
    "Designed and implemented an NLP-based system to extract structured data from unstructured text, resulting in a 40% increase in data accuracy and a 25% reduction in processing time.\n",
    "Developed and maintained NLP-based systems to detect and classify text, improving accuracy by 20% and reducing false positives by 15%.\n",
    "Developed and maintained NLP-based systems to generate natural language text, resulting in a 30% increase in customer engagement and a 25% increase in revenue.\n",
    "SKILLS & COMPETENCIES\n",
    "Natural Language Processing (NLP)\n",
    "Machine Learning\n",
    "Deep Learning\n",
    "Text Analytics\n",
    "Data Mining\n",
    "Python\n",
    "TensorFlow\n",
    "PyTorch\n",
    "Keras\n",
    "NLTK\n",
    "SpaCy\n",
    "Gensim\n",
    "Sentiment Analysis\n",
    "Named Entity Recognition\n",
    "Text Classification\n",
    "Information Extraction\n",
    "Data Visualization\n",
    "Big Data Processing\n",
    "Hadoop\n",
    "Spark\n",
    "SQL\n",
    "Git\n",
    "Docker\n",
    "RESTful APIs\n",
    "Agile Development\n",
    "Team Collaboration\n",
    "Research and Evaluation\n",
    "Problem Solving\n",
    "Communication Skills\n",
    "COURSES / CERTIFICATIONS\n",
    "Natural Language Processing Professional (NLPP) Certification\n",
    "04/2023\n",
    "International Association of Artificial Intelligence and NLP Professionals (IAAINP)\n",
    "Data Science and Machine Learning Bootcamp with Python (Udemy)\n",
    "04/2022\n",
    "Udemy\n",
    "Advanced Natural Language Processing (NLP) with Deep Learning (Coursera)\n",
    "04/2021\n",
    "deeplearning.ai\n",
    "EDUCATION\n",
    "Master of Science in Natural Language Processing\n",
    "2016 - 2020\n",
    "University of Washington\n",
    "Seattle, WA\n",
    "Natural Language Processing\n",
    "Computer Science\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample resume "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-16T21:50:29.269068Z",
     "iopub.status.busy": "2023-12-16T21:50:29.268774Z",
     "iopub.status.idle": "2023-12-16T21:50:29.284760Z",
     "shell.execute_reply": "2023-12-16T21:50:29.284004Z",
     "shell.execute_reply.started": "2023-12-16T21:50:29.269044Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "example_resume = \"\"\"Jarrett Farrell\n",
    "jarrett@farrell.com\n",
    "•\n",
    "(234) 567-8901\n",
    "•\n",
    "linkedin.com/in/jarrett-farrell\n",
    "•\n",
    "@jarrett.farrell\n",
    "Senior NLP Engineer\n",
    "Highly skilled Senior NLP Engineer with a track record of developing and implementing state-of-the-art NLP models, resulting in significant accuracy improvements and increased customer satisfaction. Collaborative team player experienced in optimizing NLP pipelines and integrating models into chatbot systems, driving efficiency gains and reducing response times. Proven ability to research and implement cutting-edge NLP techniques, achieving substantial accuracy improvements and seamless integration into various applications.\n",
    "WORK EXPERIENCE\n",
    "Senior NLP Engineer\n",
    "01/2023 – 04/2023\n",
    "Cardinal Industries\n",
    "Developed and implemented a state-of-the-art NLP model for sentiment analysis, resulting in a 25% increase in accuracy compared to existing models.\n",
    "Collaborated with a team of data scientists to optimize an NLP pipeline, reducing data pre-processing time by 40% and improving overall model training efficiency.\n",
    "Integrated NLP models into a chatbot system, leading to a 30% reduction in customer support response time and a 20% increase in customer satisfaction.\n",
    "NLP Engineer\n",
    "09/2022 – 12/2022\n",
    "Genesis Global\n",
    "Researched and implemented a novel algorithm for text summarization, achieving a 40% improvement in summarization accuracy compared to existing methods.\n",
    "Designed and developed an NLP system for question answering, resulting in a 50% increase in the system's ability to accurately answer user queries.\n",
    "Collaborated with product managers to define requirements and successfully launched an NLP-based recommendation system, leading to a 15% increase in user engagement and a 10% increase in revenue.\n",
    "NLP Engineer\n",
    "07/2022 – 09/2022\n",
    "Genesis Global\n",
    "Developed and maintained a library of NLP models and APIs, enabling seamless integration of NLP capabilities into various applications and reducing development time by 30%.\n",
    "Implemented a continuous monitoring system for NLP model performance, resulting in early detection of issues and a 20% improvement in model accuracy over time.\n",
    "Researched and implemented cutting-edge NLP techniques for text classification, achieving a 35% increase in accuracy compared to previous models.\n",
    "SKILLS & COMPETENCIES\n",
    "Expertise in Natural Language Processing (NLP)\n",
    "Proficiency in Python and NLP libraries such as NLTK, SpaCy, and Gensim\n",
    "Experience with machine learning algorithms and deep learning frameworks like TensorFlow and PyTorch\n",
    "Knowledge of text summarization and sentiment analysis techniques\n",
    "Ability to develop and implement state-of-the-art NLP models\n",
    "Experience in optimizing NLP pipelines\n",
    "Skills in integrating NLP models into systems like chatbots\n",
    "Ability to research and implement novel algorithms for NLP tasks\n",
    "Experience in designing and developing NLP systems for question answering\n",
    "Ability to collaborate with cross-functional teams, including data scientists and product managers\n",
    "Experience in launching NLP-based recommendation systems\n",
    "Skills in developing and maintaining a library of NLP models and APIs\n",
    "Ability to implement continuous monitoring systems for NLP model performance\n",
    "Knowledge of cutting-edge NLP techniques for text classification\n",
    "Strong problem-solving skills\n",
    "Excellent communication skills\n",
    "Strong understanding of linguistics and text representation techniques\n",
    "Familiarity with cloud platforms like AWS, Google Cloud, or Azure\n",
    "Knowledge of data pre-processing and cleaning techniques\n",
    "Understanding of software development methodologies and version control systems like Git.\n",
    "COURSES / CERTIFICATIONS\n",
    "Certified Data Scientist (CDS)\n",
    "07/2023\n",
    "IBM\n",
    "Natural Language Processing Specialization by deeplearning.ai (Coursera)\n",
    "07/2022\n",
    "Coursera\n",
    "Advanced Certification in Artificial Intelligence and Machine Learning by Purdue University (Simplilearn)\n",
    "07/2021\n",
    "Purdue University (Simplilearn)\n",
    "EDUCATION\n",
    "Master of Science in Natural Language Processing\n",
    "2010-2014\n",
    "University of Washington\n",
    ",\n",
    "Seattle, WA\n",
    "Natural Language Processing\n",
    "Machine Learning\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A bit of prompt engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-16T21:50:29.286278Z",
     "iopub.status.busy": "2023-12-16T21:50:29.285943Z",
     "iopub.status.idle": "2023-12-16T21:50:29.298284Z",
     "shell.execute_reply": "2023-12-16T21:50:29.297563Z",
     "shell.execute_reply.started": "2023-12-16T21:50:29.286246Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "prompt = f\"\"\"You are an NLP HR specialist. You need to decide if the person with your resume is suitable for our vacancy. To do this, look at the iconic resume: \\n{iconic_resume} \\n and the vacancy: \\n{vacancy}. Based on this, give an assessment of the relevance of the input resume and the vacancy from 1 to 5 and decide whether we should hire this candidate or not. Input resume: \\n{example_resume} \\n Answer: Let's think step by step...\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-16T21:51:23.368887Z",
     "iopub.status.busy": "2023-12-16T21:51:23.367865Z",
     "iopub.status.idle": "2023-12-16T21:51:23.375280Z",
     "shell.execute_reply": "2023-12-16T21:51:23.374296Z",
     "shell.execute_reply.started": "2023-12-16T21:51:23.368853Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def generate(model, tokenizer, prompt):\n",
    "    data = tokenizer(prompt, return_tensors=\"pt\", add_special_tokens=False)\n",
    "    data = {k: v.to(model.device) for k, v in data.items()}\n",
    "    output_ids = model.generate(\n",
    "        **data, max_new_tokens=512, use_cache=True, do_sample=True, temperature=0.2, top_p=0.95\n",
    "    )[0]\n",
    "    output_ids = output_ids[len(data[\"input_ids\"][0]) :]\n",
    "    output = tokenizer.decode(output_ids, skip_special_tokens=True)\n",
    "    return output.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-16T21:51:23.464554Z",
     "iopub.status.busy": "2023-12-16T21:51:23.464254Z",
     "iopub.status.idle": "2023-12-16T21:51:47.794638Z",
     "shell.execute_reply": "2023-12-16T21:51:47.793685Z",
     "shell.execute_reply.started": "2023-12-16T21:51:23.464530Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Relevance of the input resume: The input resume is highly relevant to the vacancy as the candidate has a strong background in NLP, with experience in developing and implementing state-of-the-art NLP models, optimizing NLP pipelines, and integrating models into chatbot systems.\n",
      "\n",
      "2. Work experience: The candidate has 12 years of experience in the field, which is in line with the job requirements.\n",
      "\n",
      "3. Skills and competencies: The candidate possesses a wide range of skills and competencies relevant to the position, including expertise in NLP, proficiency in Python, experience with machine learning algorithms and deep learning frameworks, and knowledge of text summarization and sentiment analysis techniques.\n",
      "\n",
      "4. Education: The candidate has a Master of Science in Natural Language Processing, which is in line with the educational qualification required for the position.\n",
      "\n",
      "5. Additional information: The candidate has a strong understanding of linguistics and text representation techniques, familiarity with cloud platforms, and knowledge of data pre-processing and cleaning techniques.\n",
      "\n",
      "Based on the analysis, I would give the input resume a rating of 5 out of 5 and recommend hiring this candidate for the position.\n"
     ]
    }
   ],
   "source": [
    "text = generate(model, tokenizer, prompt)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [],
   "dockerImageVersionId": 30616,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
